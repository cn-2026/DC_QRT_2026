{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de0edeb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: c:\\Users\\alexb\\Documents\\EI3\\APST1\\Data Challenge\\project_root\n",
      "Looking for data at: c:\\Users\\alexb\\Documents\\EI3\\APST1\\Data Challenge\\project_root\\data\\raw\\train\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# -------------------------\n",
    "# 1. Load the tables\n",
    "# -------------------------\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "cwd = Path.cwd()\n",
    "project_root = None\n",
    "\n",
    "# Fallback: search for the data/raw/train directory structure\n",
    "if project_root is None:\n",
    "    for p in [cwd] + list(cwd.parents):\n",
    "        if (p / 'data' / 'raw' / 'train').is_dir():\n",
    "            project_root = p\n",
    "            break\n",
    "\n",
    "if project_root is None:\n",
    "    project_root = cwd\n",
    "\n",
    "data_raw_train = project_root / 'data' / 'raw' / 'train'\n",
    "clinical_path = data_raw_train / 'clinical_train.csv'\n",
    "molecular_path = data_raw_train / 'molecular_train.csv'\n",
    "target_path = data_raw_train / 'target_train.csv'\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Looking for data at: {data_raw_train}\")\n",
    "\n",
    "if not target_path.exists():\n",
    "    raise FileNotFoundError(f'Could not find target file at {target_path}')\n",
    "if not clinical_path.exists():\n",
    "    raise FileNotFoundError(f'Could not find clinical file at {clinical_path}')\n",
    "if not molecular_path.exists():\n",
    "    raise FileNotFoundError(f'Could not find molecular file at {molecular_path}')\n",
    "\n",
    "\n",
    "target = pd.read_csv(target_path, sep=\",\", header=0,\n",
    "                     names=['ID','OS_YEARS','OS_STATUS'],\n",
    "                     dtype={'ID': str, 'OS_YEARS': float, 'OS_STATUS': float})\n",
    "\n",
    "clinical = pd.read_csv(clinical_path, sep=\",\", header=0,\n",
    "    names=['ID','CENTER','BM_BLAST','WBC','ANC','MONOCYTES','HB','PLT','CYTOGENETICS'],\n",
    "    dtype={'ID': str, 'CENTER': str, 'BM_BLAST': float, 'WBC': float,\n",
    "           'ANC': float, 'MONOCYTES': float, 'HB': float, 'PLT': float, 'CYTOGENETICS': str})\n",
    "\n",
    "molecular = pd.read_csv(molecular_path, sep=\",\", header=0,\n",
    "    names=['ID','CHR','START','END','REF','ALT','GENE','PROTEIN_CHANGE',\n",
    "           'EFFECT','VAF','DEPTH'],\n",
    "    dtype={'ID': str, 'CHR': str, 'START': float, 'END': float,\n",
    "           'REF': str, 'ALT': str, 'GENE': str, 'PROTEIN_CHANGE': str,\n",
    "           'EFFECT': str, 'VAF': float, 'DEPTH': float})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b529fbb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target shape: (3323, 3)\n",
      "Clinical shape: (3323, 9)\n",
      "Molecular shape: (10935, 11)\n"
     ]
    }
   ],
   "source": [
    "# We check that the data is loaded correctly\n",
    "print(f\"Target shape: {target.shape}\")\n",
    "print(f\"Clinical shape: {clinical.shape}\")\n",
    "print(f\"Molecular shape: {molecular.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51c4f7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 2. Convert molecular table into per-patient mutation features\n",
    "# -------------------------\n",
    "\n",
    "# Example feature engineering: binary indicator for each gene mutated\n",
    "gene_counts = molecular.groupby(['ID', 'GENE']).size().unstack(fill_value=0)\n",
    "\n",
    "# You can also include VAF summary statistics:\n",
    "vaf_stats = molecular.groupby(\"ID\")[\"VAF\"].agg(['mean','max','min']).add_prefix(\"VAF_\")\n",
    "\n",
    "# Combine molecular features\n",
    "mol_features = gene_counts.join(vaf_stats, how=\"left\").fillna(0)\n",
    "\n",
    "# -------------------------\n",
    "# 3. Merge everything into a single training table\n",
    "# -------------------------\n",
    "\n",
    "X = clinical.merge(mol_features, how=\"left\", on=\"ID\").fillna(0)\n",
    "y = target.set_index(\"ID\").loc[X[\"ID\"]][\"OS_YEARS\"]  # using OS_YEARS as target\n",
    "\n",
    "# Remove ID column\n",
    "X = X.set_index(\"ID\")\n",
    "\n",
    "# Force categorical fields to string\n",
    "categorical_cols = [\"CENTER\", \"CYTOGENETICS\"]\n",
    "for col in categorical_cols:\n",
    "    X[col] = X[col].astype(str)\n",
    "\n",
    "# Remove patients with missing survival time\n",
    "valid_idx = ~y.isna()\n",
    "X = X[valid_idx]\n",
    "y = y[valid_idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8066f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        CENTER  BM_BLAST     WBC   ANC  MONOCYTES    HB    PLT  \\\n",
      "ID                                                               \n",
      "P132697    MSK      14.0    2.80  0.20       0.70   7.6  119.0   \n",
      "P132698    MSK       1.0    7.40  2.40       0.10  11.6   42.0   \n",
      "P116889    MSK      15.0    3.70  2.10       0.10  14.2   81.0   \n",
      "P132699    MSK       1.0    3.90  1.90       0.10   8.9   77.0   \n",
      "P132700    MSK       6.0  128.00  9.70       0.90  11.1  195.0   \n",
      "...        ...       ...     ...   ...        ...   ...    ...   \n",
      "P121826     VU       1.0    2.50  1.02       0.20  10.2   78.0   \n",
      "P121827     VU       1.5    8.10  2.66       0.45  11.3   40.0   \n",
      "P121830     VU       0.0    1.80  0.55       0.29   9.4   86.0   \n",
      "P121853     VU       5.0    1.37  0.37       0.11  11.4  102.0   \n",
      "P121834     VU       0.0    2.70  0.72       0.23   8.2  239.0   \n",
      "\n",
      "                                              CYTOGENETICS  ABL1  ARID1A  ...  \\\n",
      "ID                                                                        ...   \n",
      "P132697                    46,xy,del(20)(q12)[2]/46,xy[18]   0.0     0.0  ...   \n",
      "P132698                                              46,xx   0.0     0.0  ...   \n",
      "P116889                 46,xy,t(3;3)(q25;q27)[8]/46,xy[12]   0.0     0.0  ...   \n",
      "P132699                  46,xy,del(3)(q26q27)[15]/46,xy[5]   0.0     0.0  ...   \n",
      "P132700                46,xx,t(3;9)(p13;q22)[10]/46,xx[10]   0.0     0.0  ...   \n",
      "...                                                    ...   ...     ...  ...   \n",
      "P121826               47~49,xy,+21,+21,+22[cp11]/46,xy[10]   0.0     0.0  ...   \n",
      "P121827     44,xx,inv(2)(p25q31),-4,del(5)(q12q33),-18[20]   0.0     1.0  ...   \n",
      "P121830     46,xy,del(20)(q11.2q13.1)[4]/45,xy,idem,-7[16]   0.0     0.0  ...   \n",
      "P121853  46,xx,del(1)(p34)[5]/45,xx,sl,-18[12]/46,xx,sd...   0.0     0.0  ...   \n",
      "P121834                                          46,xy[20]   0.0     0.0  ...   \n",
      "\n",
      "         U2AF2  WHSC1  WT1  ZBTB33  ZMYM3  ZNF318  ZRSR2  VAF_mean  VAF_max  \\\n",
      "ID                                                                            \n",
      "P132697    0.0    0.0  0.0     0.0    0.0     0.0    0.0  0.251578   0.4220   \n",
      "P132698    0.0    0.0  0.0     0.0    0.0     0.0    0.0  0.272867   0.2825   \n",
      "P116889    0.0    0.0  1.0     0.0    0.0     0.0    0.0  0.039333   0.0480   \n",
      "P132699    0.0    0.0  0.0     0.0    0.0     0.0    1.0  0.209227   0.4770   \n",
      "P132700    0.0    0.0  0.0     0.0    0.0     0.0    0.0  0.472100   0.4721   \n",
      "...        ...    ...  ...     ...    ...     ...    ...       ...      ...   \n",
      "P121826    0.0    0.0  0.0     0.0    0.0     0.0    0.0  0.169000   0.5010   \n",
      "P121827    0.0    0.0  0.0     0.0    0.0     0.0    0.0  0.427500   0.8190   \n",
      "P121830    0.0    0.0  0.0     0.0    0.0     0.0    0.0  0.244650   0.4390   \n",
      "P121853    0.0    0.0  0.0     0.0    0.0     0.0    0.0  0.184250   0.2690   \n",
      "P121834    0.0    0.0  0.0     0.0    0.0     0.0    0.0  0.275220   0.3450   \n",
      "\n",
      "         VAF_min  \n",
      "ID                \n",
      "P132697   0.0300  \n",
      "P132698   0.2661  \n",
      "P116889   0.0350  \n",
      "P132699   0.0490  \n",
      "P132700   0.4721  \n",
      "...          ...  \n",
      "P121826   0.0510  \n",
      "P121827   0.0360  \n",
      "P121830   0.0280  \n",
      "P121853   0.0290  \n",
      "P121834   0.0230  \n",
      "\n",
      "[3173 rows x 135 columns]\n"
     ]
    }
   ],
   "source": [
    "# We check the integrity of the merged data\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64241475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RÂ² on test: 0.17303938312621658\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# 4. Build preprocessing + model pipeline\n",
    "# -------------------------\n",
    "\n",
    "# Categorical columns from clinical features\n",
    "categorical_cols = [\"CENTER\", \"CYTOGENETICS\"]\n",
    "numeric_cols = [c for c in X.columns if c not in categorical_cols]\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_cols),\n",
    "        (\"num\", \"passthrough\", numeric_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# GradientBoostingRegressor is stable for noisy biomedical data\n",
    "model = GradientBoostingRegressor(\n",
    "    n_estimators=400,\n",
    "    learning_rate=0.03,\n",
    "    max_depth=3,\n",
    "    subsample=0.8\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", model)\n",
    "])\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# 5. Train/test split and training\n",
    "# -------------------------\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81954a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines.utils import concordance_index\n",
    "from sksurv.metrics import concordance_index_ipcw\n",
    "from sksurv.util import Surv\n",
    "\n",
    "# -------------------------\n",
    "# 6. Evaluating model performance\n",
    "# -------------------------\n",
    "\n",
    "time_test = y_test.values\n",
    "status_test = target.set_index(\"ID\").loc[X_test.index][\"OS_STATUS\"].astype(bool).values\n",
    "\n",
    "c_index = concordance_index(\n",
    "    event_times=time_test,\n",
    "    predicted_scores=pred,\n",
    "    event_observed=status_test\n",
    ")\n",
    "\n",
    "print(\"C-index:\", c_index)\n",
    "\n",
    "# Need train data for censoring distribution\n",
    "time_train = y_train.values\n",
    "status_train = target.set_index(\"ID\").loc[X_train.index][\"OS_STATUS\"].astype(bool).values\n",
    "\n",
    "# scikit-survival requires its own structured array format:\n",
    "y_train_struct = Surv.from_arrays(status_train, time_train)\n",
    "y_test_struct  = Surv.from_arrays(status_test, time_test)\n",
    "\n",
    "c_index_ipcw = concordance_index_ipcw(\n",
    "    y_train_struct,\n",
    "    y_test_struct,\n",
    "    pred\n",
    ")[0]   # first entry is the IPCW-c-index\n",
    "\n",
    "print(\"IPCW C-index:\", c_index_ipcw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d059e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 6. Predict survivability score for all patients\n",
    "# -------------------------\n",
    "\n",
    "survivability_score = pipeline.predict(X)\n",
    "\n",
    "# Attach score to IDs\n",
    "output = pd.DataFrame({\n",
    "    \"ID\": X.index,\n",
    "    \"SURVIVABILITY_SCORE\": survivability_score\n",
    "})\n",
    "\n",
    "print(output.head())\n",
    "\n",
    "# Save to CSV\n",
    "output.to_csv(\"survivability_predictions.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
